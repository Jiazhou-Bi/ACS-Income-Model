---
title: "Personal Total Income of Individual in the United States of America in 2023"
subtitle: "A Predictive Model Using the American Community Survey Data"
author: 
  - Justin (Jiazhou) Bi and Weiyang Li
thanks: "Inspired and instructed by: https://github.com/RohanAlexander/marriage. All the project related files can be found at: https://github.com/Jiazhou-Bi/ACS-Income-Model/tree/main."
date: Oct 25, 2024
date-format: long
abstract: "This project aims to build a predictive model for personal total income using various demographic attributes, such as marital status, occupation, and residing state. We explored three popular machine learning algorithms: Random Forest, Linear Regression, and Extreme Gradient Boosting. Ultimately, Extreme Gradient Boosting was selected due to its superior predictive performance. While the model achieved a high R-squared value, it also exhibited a high Mean Squared Error, indicating challenges in accurately predicting all data points. Future steps for improving the model may involve incorporating additional demographic features to enhance model accuracy and reduce errors. Additionally, fine-tuning hyperparameters, experimenting with feature engineering, and handling outliers could further improve performance."

format: pdf
jupyter: python3 
number-sections: true
bibliography: references.bib
---

# Introduction {#sec-introduction}

Income is a fundamental concept as it affects nearly every member of society, influencing access to resources, quality of life, and overall economic stability. At the same time, it is also a highly complex concept to define, as it can be interpreted differently depending on various perspectives, such as economic, social, legal, and tax purposes. Therefore, we must examine various demographical factors that may impact income to understand its concept better. Our project defines income as "all forms of net financial resources generated or lost from work, investments, or other activities." This project aims to predict personal income using data from the 2023 American Community Survey (ACS) (@ipums_usa_v15). The ACS provides detailed demographic information, including age, education, employment, marital status, mortgage status, veteran status, etc... As a result, it provides a robust dataset for studying potential factors that may influence income.

Due to the timeframe limitations, the findings of this project are specifically applicable to the 2023 dataset. As such, the results may vary across different periods, and their generalizability has not been assessed within this project. The raw data used in this analysis was sourced from IPUMS using the IPUMS API. (@ipums_api) We utilized pandas (@pandas) for data processing, and data visualization was carried out using Seaborn. (@seaborn) Additionally, all tables presented in this report were generated with Plotly. (@plotly)

Income inequality is a serious problem and can lead to significant consequences and it may affect social structure, economic stability, as well as policy-making processes. Researchers found that demographic factors, such as education level and occupation type, can significantly impact an individual's financial standing. (@Autor_2013) Similarly, social relationships, such as marital status and household characteristics, affect income dynamics. (@WaiteGallagher_2000) Therefore, applying machine learning models to analyze the ACS dataset and using the information mentioned to predict personal income is reasonable.

We have chosen 2023 ACS dataseet because it offers many demographical details, as well as self-reported total income of the individuals. The sample is also representative and covers all geographical locations in the USA. Furthermore, it provides easy access to their database through API. We will employ advanced predictive models, including random forest, lineaer regression, and extreme gradient boosting machine to estimate personal income based on demographic factors to provide insights into which potential factors have the most significant impact on personal income. We hope the findings generated from our project can provide insights to policy-making process so that we can, hopefully, reduce income inequality and support further economic development in the future. 

If we can successfully predict personal income using demographic information from the survey, this analysis will be able to contribute to a nuanced understanding of the American economy in 2023. It can help to reveal how demographic changess, educational attainment, and employment status/type can impact personal income. On the other hand, if the model cannot predict personal income with a high degree of confidence, this would suggest that the factors included in the analysiscannot not fully capture the intricacies of economic behavior and individual circumstances. As a result, additional variables, such as detailed education background like school of graduation, languages spoken, health status, etc, might be necessary in accurately predicting income. 

# Data {#sec-data}

The dataset used here is downloaded from the Toronto Open Data website via @TorontoOpenData. This dataset contains all the reported crimes that happened in Toronto from 2014 to 2023. This dataset is grouped by the year of the reported crime, its category and belonging subtype, and the count of the subtype being reported and cleared for that year for each division. Because I am examining the crime pattern in the city, I have dropped the division information and aggregated the existing data according to their subtype and the year of the crime being reported. In the following subsections, I will review all the variables used in this report and provide some basic descriptive statistics. The first five rows of the cleaned data used for analysis are attached (@tbl-table1).

```{python}
#| label: tbl-table1
#| tbl-cap: Example of Cleaned Data
#| warning: false
#| echo: false

import pandas as pd
data = pd.read_parquet('../data/02-analysis_data/cleaned_data.parquet')
data.index = data.index + 1
data.head()
# styled_data = data.head().style.format({'ClearRate': "{:.2f}"}).hide().set_table_styles([{"selector":"th.col_heading,td","props":[("width","100px")]}])
# styled_data
#data.values[:5]
#print(data.head().to_string(index=False))

```

## Report Year
The report year variable is the number of crimes being reported. In this dataset, the data spans from 2014 to 2023, encompassing ten years. No month or date information was given; thus, there are only ten different values for this variable in chronological order.

## Category
The category includes information about the nature of the crime. There are six crime categories: Crimes Against Property, Crimes Against the Person, Other Federal Statute Violations, Other Criminal Code Violations, Controlled Drugs and Substances Act, and Criminal Code Traffic. They are listed in the table below (@tbl-table2).

```{python}

#| echo: false
#| label: tbl-table2
#| warning: false
#| tbl-cap: Six Crime Categories
# import pandas as pd
# import plotly.graph_objects as go
# data = pd.read_csv('../data/analysis_data/analysis_data.csv')
# unique_category = data.Category.unique()
# category_df = pd.DataFrame(unique_category, columns=['Categories'])
# category_df.index = category_df.index + 1
# category_df
```

## Subtype
There exist multiple subtypes under each crime category. The following is an exhaustive table (@tbl-table3) of all crimes' subtypes and their respective category.

```{python}
#| echo: false
#| label: tbl-table3
#| warning: false
#| tbl-cap: Crime Categories and Subtypes
# import pandas as pd
# data = pd.read_csv('../data/analysis_data/analysis_data.csv')
# unique_category_subtype_data = data.drop_duplicates(subset=['Category', 'Subtype'])
# unique_category_subtype_df = unique_category_subtype_data[['Category', 'Subtype']]
# unique_category_subtype_df = unique_category_subtype_df.sort_values(by=['Category','Subtype'],ascending=True)
# unique_category_subtype_df.reset_index(drop=True, inplace=True)
# unique_category_subtype_df.index = unique_category_subtype_df.index + 1
# unique_category_subtype_df
```

## Count
In the original table, this value is grouped by the subtype of the crime, the division, and the year when the crime was reported. The original count indicates the number of a specific subtype of crime reported within a particular division for the year. However, as mentioned before, because I am only interested in all the crimes in the City of Toronto, I have dropped the division information and aggregated the count from all the divisions to a single value. Therefore, for each subtype of the crimes, a total count of that subtype is reported in a single year.

## Count_Cleared
These are the counts of crimes identified as cleared. In plain words, these are crimes that are dealt/solved. I have taken the same approach for this column as the previous one. After cleaning the data,f, or each subtype of the crimes, there is a total count of that subtype being reported that is also cleared in a single year.

## Case_Clearing_Rate
This column was not included in the raw dataset but was created by dividing the cleared crimes by total crimes. A higher case-clearing rate for a particular subtype of crime usually suggests a higher effectiveness of law enforcement in dealing with this subtype of crime. The value is ranged from 0 to 100%.

# Exploratory Data Analysis {#sec-eda}

# Model {#sec-model}

Our modeling strategy aims to explore the relationship between personal characteristics and income. We implemented three models: Linear Regression with Interaction Terms, Random Forest, and XGBoost, each chosen for their unique strengths in prediction and interpretation.

## Linear Regression Model with Interaction Term {#sec-linear-regression-model-with-interaction-term}

### Model set-up

We implemented a linear regression model with an interaction term to explore the relationship between personal characteristics and income. The general form of the model is:

$$
y=\beta_0+\beta_1X_1+\beta_2X_2+...+\beta_nX_n+\beta_{\text{interaction}}(X_i\times X_j)+\epsilon
$$

where:

-   y represents the total income (`INCTOT`),

-   $X_1, X_2, ... , X_n$ are the predictor variables, including both categorical and numerical features,

-   $X_i \times X_j$ is the interaction term between education and sex (`EDUC_SEX_INTERACTION`)

-   $\beta_0$ is the intercept,

-   $\beta_1, \beta_2, ... , \beta_n, \beta_{\text{interaction}}$ are the coefficients for the respective predictors and interaction term.

To ensure the robustness of our linear regression model, we conducted a series of steps aimed at minimizing multicollinearity and improving model interpretability. Initially, we included all relevant predictor variables, both categorical and numerical, to explore the full range of relationships between personal characteristics and income. Next, we calculated the Variance Inflation Factor (VIF) for each predictor to identify potential multicollinearity issues. Typically, a VIF value greater than 10 indicates problematic multicollinearity, which can distort the model's estimates. In our analysis, variables such as `VESTAT` (Veteran Status) and `AGE` had VIF values exceeding 13, suggesting they were highly correlated with other predictors. To address this, we removed these high-VIF variables from the model. Afterward, we refit the linear regression model using the reduced set of predictors, which resulted in improved performance metrics, including a lower Mean Squared Error and a more interpretable set of coefficients.

Note that according to our previous analysis in @sec-eda, the interaction term, `EDUC_SEX_INTERACTION`, was included to capture the combined effect of education level and gender on income. This allowed us to model the non-linear relationship between these two variables and their joint impact on the outcome variable.

::: {#tbl-coefficients}
\begin{center}
Table 1: Coefficients from the Linear Regression Model
\end{center}

| Feature                     | Coefficient |
|-----------------------------|-------------|
| cat__MORTGAGE             | 11267.90    |
| num__AGE                  | 415.91      |
| cat__STATEICP             | 126.39      |
| cat__IND1990              | -43.18      |
| cat__OCC2010              | -139.55     |
| num__EDUC_SEX_INTERACTION | -1832.32    |
| cat__MARST                | -5541.39    |
| cat__GQ                   | -7956.89    |
| cat__SCHLTYPE             | -16320.74   |
:::

*Table 1: Linear Regression Coefficients Table.*

We run the model in Python [@cite_python] using the `scikit-learn` package [@cite_sklearn]. We use the default settings for the `LinearRegression` function from `scikit-learn`. We use the `statsmodels` package [@cite_statsmodels] to calculate the VIF for each predictor.

### Model Justification

In evaluating our model's performance, we selected key metrics to assess both its fit and predictive accuracy, including the Variance Inflation Factor (VIF), R-squared ($R^2$), and Mean Squared Error (MSE). These metrics were chosen to provide a comprehensive evaluation of the model's robustness and reliability in capturing the relationship between personal characteristics and income.

The VIF was used to diagnose multicollinearity among predictors, helping us ensure that no variables were highly correlated, which could distort the interpretation of the model's coefficients.

::: {#tbl-VIF}
\begin{center}
Table 2: Variance Inflation Factors (VIF) for Predictor Variables
\end{center}

| Feature                  | VIF       |
|--------------------------|-----------|
| cat__STATEICP            | 3.242254  |
| cat__GQ                  | 1.002419  |
| cat__MORTGAGE            | 2.658013  |
| cat__MARST               | 1.741158  |
| cat__SCHLTYPE            | 1.239412  |
| cat__OCC2010             | 3.187731  |
| cat__IND1990             | 8.490997  |
| num__AGE                 | 7.871046  |
| num__EDUC_SEX_INTERACTION| 6.945850  |
:::

*Table 2: This table displays the Variance Inflation Factors (VIF) for each of the predictor variables in the model. VIF values greater than 10 indicate potential multicollinearity issues.*

We chose $R^2$ as it provides a measure of how well the model explains the variance in the dependent variable, making it an important indicator of the model’s explanatory power. The MSE was selected to quantify the average squared difference between observed and predicted values, offering a clear view of the model’s prediction error.

::: {#tbl-modelperformance}
\begin{center}
Table 3: Model Performance Metrics
\end{center}

| Metric                     | Value              |
|----------------------------|--------------------|
| R-squared                  | 0.0774938018       |
| Adjusted R-squared         | 0.0774637241       |
| Mean Squared Error (MSE)   | 7,448,800,507.01   |
| Root Mean Squared Error (RMSE) | 86,306.43        |
:::

*Table 3: This table presents the performance metrics of the linear regression model, including MSE, RMSE, R-squared, and Adjusted R-squared. These metrics are used to assess the model's fit and predictive accuracy.*

Additionally, residual analysis was conducted by plotting residuals against fitted values to check for randomness around zero, ensuring that the model satisfied the assumptions of linearity and homoscedasticity.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.5\textwidth]{../other/graphs/LinearModelResidual1.png}
\caption{Linear Model Residuals Plot}
\label{fig:residual-linear1}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.5\textwidth]{../other/graphs/LinearModelResidual2.png}
\caption{Linear Model Residuals vs. Predicted Values Plot}
\label{fig:residual-linear2}
\end{figure}

We use the statsmodels package [@cite_statsmodels] to calculate the VIF for each predictor. We use the matplotlib [@cite_matplotlib] and seaborn [@seaborn] to visualize the residuals. We use the scikit-learn [@cite_sklearn] package to calculate the $R^2$ score.

## Random Forest Model {#sec-random-forest}

### Model set-up

To analyze the non-linear relationship between personal characteristics and income, we employed a Random Forest model. Random Forest is an ensemble learning method that builds multiple decision trees and averages their predictions, reducing overfitting and capturing complex, non-linear relationships in the data. We utilized Bagging (Bootstrap Aggregating) and random feature selection to enhance model performance and reduce overfitting. Bagging involves generating multiple bootstrap samples from the original training set, with each sample used to train an independent decision tree. By averaging the predictions of multiple trees, Bagging reduces the variance of the model, thereby improving its robustness. Additionally, Random Forest introduces further randomness by selecting a subset of features at each split, which reduces correlation among trees and improves the model’s generalization ability.

To optimize the model, we conducted hyperparameter tuning, focusing on two key parameters: `n_estimators` (the number of trees) and `max_depth` (the maximum depth of each tree). Increasing `n_estimators` typically decreases model variance and improves stability, but too many trees can result in diminishing returns with increased computation time. Initially, we set `n_estimators` to 100, but through Grid Search, we tested values of 100, 200, and 300 and found that 300 trees yielded the best performance. Similarly, the `max_depth` parameter controls the complexity of the trees. While deeper trees can capture more intricate data patterns, they may also overfit. We initially set `max_depth` to 15 and test 10, 15, 20 but found that reducing it to 10 during hyperparameter tuning improved generalization by avoiding overfitting. Additionally, we tuned `min_samples_split` and `min_samples_leaf` to prevent overfitting by ensuring that nodes have a sufficient number of samples before splitting.

We run the model in Python [@cite_python] using the scikit-learn package [@cite_sklearn] and pandas [@pandas]. We used the GridSearchCV function from scikit-learn for hyperparameter tuning and subsampled the training data using pandas. The RandomForestRegressor function from scikit-learn was employed for model fitting.

### Model Justification

To assess the performance of our Random Forest model, we evaluated several key metrics, including Mean Squared Error (MSE), Root Mean Squared Error (RMSE), feature importance, and residual analysis. These evaluations provided insights into the model’s predictive accuracy, interpretability, and overall fit.

First, we calculated the Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) to assess the overall prediction accuracy of the model. These metrics provided insight into how well the model captured the variance in income based on the selected features.

::: {#tbl-randomforestMSE}
\begin{center}
Table 4: Best Random Forest Model Performance Metrics
\end{center}

| Metric          | Value            |
|-----------------|------------------|
| Best Model MSE  | 6,057,429,750.02 |
| Best Model RMSE | 77,829.49        |
:::

*Table 4: This table shows the Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) for the best-tuned Random Forest model, demonstrating the model's performance after hyperparameter tuning.*

Additionally, we performed a feature importance analysis, which allowed us to understand the relative significance of each predictor variable in determining income. This is particularly useful for verifying that the model identifies the key factors influencing income as expected.

::: {#tbl-randomforestimportance}
\begin{center}
Table 5: Feature Importance in the Best Random Forest Model
\end{center}

| Feature         | Importance |
|-----------------|------------|
| cat\_\_EDUC_new | 0.337065   |
| cat\_\_IND1990  | 0.243454   |
| num\_\_AGE      | 0.193926   |
| cat\_\_SEX      | 0.149342   |
| cat\_\_MARST    | 0.055948   |
| cat\_\_MORTGAGE | 0.013064   |
| cat\_\_SCHLTYPE | 0.004251   |
| cat\_\_VETSTAT  | 0.002948   |
| cat\_\_OWNERSHP | 0.000000   |
:::

*Table 5: This table lists the feature importance values for the best-performing Random Forest model. The higher the importance value, the more significant the feature is in predicting the target variable (income).*

We also conducted a residual analysis by plotting the residuals (the difference between actual and predicted values) against the predicted values. This step helped us evaluate whether the model appropriately captured the underlying patterns in the data, ensuring that there were no significant biases or violations of model assumptions.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.5\textwidth]{../other/graphs/RandomForestResidual.png}
\caption{Random Forest Model Residuals vs. Predicted Values Plot}
\label{fig:residual-randomforest}
\end{figure}

The feature importances were extracted from the best model using RandomForestRegressor from scikit-learn [@cite_sklearn] and displayed using pandas [@pandas]. We use the matplotlib [@cite_matplotlib] to visualize the residuals.

## XGBoost {#sec-xgboost}

### Model set-up

XGBoost (Extreme Gradient Boosting) is a powerful machine learning algorithm that builds an ensemble of decision trees using gradient boosting techniques. In gradient boosting, each subsequent tree is trained to correct the residuals of the previous trees, iteratively improving the model’s predictive accuracy. XGBoost enhances this process by incorporating regularization techniques to control overfitting, making it an ideal choice for capturing complex, non-linear relationships in data.

To optimize the performance of our XGBoost model, we employed GridSearchCV to conduct hyperparameter tuning. We explored a range of hyperparameters to find the optimal configuration for our dataset. The grid search included the learning rate (`learning_rata`), max depth (`max_depth`), number of trees (`n_estimators`), and minimum child weight (`min_child_weight`). Specifically, we tested learning rates of 0.01, 0.05, and 0.1, tree depths of 4, 6, and 8, and `n_estimators` values of 100, 200, and 300. Using GridSearchCV with a cross-validation fold of 3, we systematically evaluated different combinations of these hyperparameters. The model was evaluated using negative Mean Squared Error (MSE) as the scoring metric. The optimal model used a learning rate of `0.1`, a maximum tree depth of `6`, a minimum child weight of `5`, and `300` boosting rounds. This configuration provided a good balance between model complexity and predictive accuracy, capturing important non-linear relationships while minimizing overfitting.

We implemented the XGBoost model in Python [@cite_python] using the scikit-learn package [@cite_sklearn], with pandas [@pandas] for data processing and xgboost [@cite_xgboost] for model fitting. The initial model was trained using default parameters of the XGBRegressor function, which was subsequently fine-tuned using GridSearchCV from scikit-learn [@cite_sklearn] for hyperparameter optimization. 

### Model Justification

Similar to the Random Forest model, the XGBoost model was trained on a 70-30 train-test split. We evaluated the model's performance using Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) to assess its predictive accuracy.

::: {#tbl-XGBoostMSE}
\begin{center}
Table 6: XGBoost Model Performance Metrics
\end{center}

| Metric                         | Value            |
|--------------------------------|------------------|
| Mean Squared Error (MSE)       | 5,191,183,577.52 |
| Root Mean Squared Error (RMSE) | 72,049.87        |
:::

*Table 6: This table shows the Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) for the final XGBoost model, reflecting its predictive accuracy.*

We performed a residual analysis by plotting the residuals against the predicted values to assess the model's fit. This allowed us to check whether the XGBoost model accurately captured the patterns in the data and to verify that no major biases or violations of model assumptions were present.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.5\textwidth]{../other/graphs/XGBoostResidual.png}
\caption{XGBoost Model Residuals vs. Predicted Values Plot}
\label{fig:residual-XGBoost}
\end{figure}

We also performed cross-validation to ensure the robustness of the XGBoost model. This technique allowed us to evaluate the model’s performance across different subsets of the data, helping to confirm that the model generalizes well and is not overly sensitive to any particular portion of the training data.

::: {#tbl-XGBoostCV}
\begin{center}
Table 7: XGBoost Cross-Validation Performance
\end{center}

| Metric                | Value     |
|-----------------------|-----------|
| Cross-Validation RMSE | 71,994.55 |
:::

*Table 7: This table shows the Root Mean Squared Error (RMSE) from cross-validation, demonstrating the model’s performance across different subsets of the data.*

We used matplotlib [@cite_matplotlib] to perform a residual analysis against the predicted values from the XGBoost model. We performed cross-validation using cross_val_score function from scikit-learn  [@cite_sklearn] to evaluate the robustness of the model. 

# Results {#sec-results}

## Linear Regression Model with Interaction Term

### Linear Regression Results

Table \ref{tbl-coefficients} provides the coefficients for each predictor in the model. The coefficients represent the estimated change in the target variable (income) for a one-unit change in the predictor, holding all other variables constant.

The largest positive effect on income is observed for `cat_MORTGAGE`, which has a coefficient of 11,267.90. This suggests that individuals with a mortgage tend to have significantly higher incomes compared to those without, when other factors are held constant. Additionally, the coefficient for `num__AGE` is 415.91, indicating that income tends to increase with age, though the effect size is relatively small.

On the other hand, some predictors have negative effects on income. The variable `cat__SCHLTYPE` (school type) has the largest negative coefficient of -16,320.74, suggesting that attending certain types of schools might be associated with lower income levels. Similarly, `cat__GQ` and `cat__MARST` (marital status) have negative coefficients of -7,956.89 and -5,541.39, respectively, implying that certain marital statuses or living arrangements are associated with lower income levels.

Interestingly, the interaction term `num__EDUC_SEX_INTERACTION` has a negative coefficient of -1,832.32, suggesting that the relationship between education and income may differ by gender. The negative value could indicate that the combined effect of education and gender has a suppressing effect on income for certain groups.

### Model Performance

As shown in Table \ref{tbl-modelperformance}, the linear regression model explains a small portion of the variance in income, as evidenced by the R-squared value of 0.0775, which indicates that only 7.75% of the variability in income is explained by the predictors in the model. The Adjusted R-squared, which adjusts for the number of predictors, is slightly lower at 0.0775, confirming that the inclusion of additional predictors did not drastically improve the model’s explanatory power.

Furthermore, the model’s Mean Squared Error (MSE) is 7,448,800,507, and the Root Mean Squared Error (RMSE) is 86,306.43, suggesting that the model's predictions deviate significantly from the actual income values. These performance metrics indicate that the linear regression model has limited predictive accuracy for this dataset.

### Residual Analysis

The residual analysis helps evaluate the linear regression model's performance. The residual histogram as shown in Figure \ref{fig:residual-linear1} shows a strong right skew, indicating that while most predictions are close to the actual values, the model struggles with higher incomes. The long tail suggests significant under-prediction for some individuals.

In the residuals vs. predicted values plot as shown in Figure \ref{fig:residual-linear2}, the residuals exhibit a funnel shape, showing increasing variance as predicted income rises. This indicates heteroscedasticity, meaning the model's error increases for higher predicted values. Overall, the analysis suggests that the linear model fits well for lower incomes but underperforms for higher-income predictions, implying a need for more complex models to better capture these relationships.

## Random Forest

We employed a Random Forest model to predict income, tuning several hyperparameters to improve model performance. The best model was achieved with the following parameters: **max_depth=10**, **min_samples_leaf=4**, **min_samples_split=10**, and **n_estimators=300**. As we shown in Table \ref{tbl-randomforestMSE}, the final model had a Mean Squared Error (MSE) of 6,057,429,750 and a Root Mean Squared Error (RMSE) of 77,829.49, indicating a substantial improvement in prediction accuracy compared to the linear regression model.

### Feature Importance

The Random Forest model, Table \ref{tbl-randomforestimportance}, also allows for an examination of feature importance, which ranks the variables by their contribution to the model's predictions. The most important features in the model are:

-   `cat__EDUC_new` (Education level) with an importance score of 0.337, indicating that education is the most significant factor affecting income in this model.

-   `cat__IND1990` (Industry) has an importance score of 0.243, suggesting that the industry in which a person works is also a major determinant of income.

-   `num__AGE` (Age) comes in third with a score of 0.194, implying that age plays a substantial role in income prediction.

Other variables, such as `cat__SEX` (Sex) and `cat__MARST` (Marital Status), show moderate importance, while factors like `cat__MORTGAGE` and `cat__SCHLTYPE` (School Type) have much smaller impacts. Interestingly, `cat__OWNERSHP` (Home Ownership) has no contribution to the model, as its importance score is 0.000.

### Residual Analysis

The residuals from the Random Forest model as shown in Figure \ref{fig:residual-randomforest} were analyzed similarly to the linear model. The residuals plot, comparing predicted values with residuals, shows less heteroscedasticity compared to the linear model, suggesting that the Random Forest model handles the data more effectively, particularly for higher income levels. However, some degree of variability in the residuals still increases with predicted income, indicating that further tuning or model adjustments may be necessary for optimal performance.

## XGBoost

The XGBoost model, a gradient boosting algorithm, was optimized using a hyperparameter grid search, yielding the best parameters: **learning_rate=0.1**, **max_depth=6**, **min_child_weight=5**, and **n_estimators=300**. These parameters were selected to balance model complexity and overfitting control. As we shown in Table \ref{tbl-XGBoostMSE}, the final model achieved a Mean Squared Error (MSE) of 5,191,183,577.52 and a Root Mean Squared Error (RMSE) of 72,049.87, making it the best-performing model among the three evaluated.

### Model Performance

The XGBoost model’s Cross-Validation RMSE (Table \ref{tbl-XGBoostCV}) was 71,994.55, which aligns closely with the final RMSE, indicating that the model generalizes well across different data subsets. This consistency in performance suggests that XGBoost effectively captures the relationship between predictors and income without overfitting.

### Residual Analysis

The residuals vs. predicted values plot as shown in Figure \ref{fig:residual-XGBoost} shows a similar pattern to the Random Forest model, with residuals clustering around zero for lower predicted values but spreading out for higher predicted incomes. However, compared to the Random Forest model, the XGBoost residuals show a slightly narrower spread, particularly at the higher income levels, indicating that XGBoost handles high-income predictions somewhat better. Nonetheless, some degree of heteroscedasticity remains, as the spread increases with predicted income.

# Discussion {#sec-discussion}

In this analysis, we explored three different models—Linear Regression, Random Forest, and XGBoost—to predict income based on various demographic and categorical factors. Each model provided valuable insights into the relationship between income and predictors such as education, age, industry, and gender. Among the models, XGBoost demonstrated the best performance in terms of predictive accuracy, as evidenced by its lower RMSE and superior handling of complex data interactions. However, this does not mean it is without limitations or that further improvements cannot be made.

## Key Findings

One consistent finding across all models is the significant impact of education and industry on income. These factors were consistently ranked as the most important predictors in both Random Forest and XGBoost models. Age also played an important role but to a lesser extent, while variables such as marital status and sex showed moderate influence.

The residual analysis revealed that none of the models perfectly fit the data, particularly for higher income levels. Both Random Forest and XGBoost exhibited a pattern of increasing residual variance (heteroscedasticity) as predicted income increased, which suggests that the models struggled to accurately predict high-income values. Linear Regression, while more interpretable, performed the worst in terms of accuracy, especially for non-linear relationships between the predictors and income.

Despite the overall success of XGBoost, it is clear that there are areas where the model's performance could be further refined.

## Weaknesses and Limitations

One major limitation encountered throughout the analysis was the skewness of the income distribution. The income data is heavily left-skewed, with most individuals earning relatively low amounts and a few individuals earning substantially higher incomes. This skewness likely contributed to the residual patterns we observed, particularly in the linear and Random Forest models.

We attempted to address this by applying a logarithmic transformation to income in an effort to normalize the data. However, this transformation did not lead to substantial improvements in model performance. Even after the transformation, the residual patterns remained, indicating that the underlying relationships between predictors and income might require more sophisticated modeling approaches than simple transformations can provide.

Another potential solution—though not ideal—would be to exclude extreme income values from the analysis. Removing high-income outliers might reduce the heteroscedasticity issue and result in a better fit for the majority of the population. However, excluding high-income individuals would also mean losing valuable information about the upper end of the income distribution, which is crucial for a complete analysis. Before taking this step, it would be necessary to justify it based on domain-specific knowledge or further data exploration.

## Next Steps

Looking forward, there are several potential avenues for further research and model improvement:

-   While we focused on standard predictors like age, education, and industry, additional variables or interaction terms might improve model performance. For example, interactions between age and education, or industry and gender, could capture more nuanced relationships.

-    Instead of removing high-income individuals, more sophisticated outlier treatment techniques could be applied. For instance, applying quantile regression or using robust regression models might help better model extreme values without distorting the broader data patterns.

-   The skewness in income distribution poses a significant challenge for modeling. Exploring techniques like synthetic data generation for high-income individuals or applying weighting schemes to account for data imbalance might help the models better capture the variance across all income levels.

In conclusion, while XGBoost provided the most accurate results, there is room for improvement in handling skewed data and better modeling high-income individuals. Future work will focus on addressing these issues while exploring more advanced modeling techniques and feature engineering to enhance predictive performance further.

\newpage

# Appendix

## Data Cleaning

\newpage

# References